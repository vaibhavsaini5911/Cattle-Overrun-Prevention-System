{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bSSKMHgks-tK",
    "outputId": "b2475681-ee30-4e29-8456-68117e2d0618"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 18 16:43:48 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   56C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hbcw0js4pQ-P"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imutils import paths\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import imutils\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JDGcPlGXrfyq",
    "outputId": "bb89cba3-8ce6-4d65-9fb2-71ca312d6d05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FkbevHzxpbaE"
   },
   "outputs": [],
   "source": [
    "!unzip '/content/drive/My Drive/African_wildlife/images/buffalo.zip' -d '/content/drive/My Drive/African_wildlife/images/buffalo'\n",
    "!unzip '/content/drive/My Drive/African_wildlife/images/elephant.zip' -d '/content/drive/My Drive/African_wildlife/images/elephant'\n",
    "!unzip '/content/drive/My Drive/African_wildlife/images/zebra.zip' -d '/content/drive/My Drive/African_wildlife/images/zebra'\n",
    "!unzip '/content/drive/My Drive/African_wildlife/images/rhino.zip' -d '/content/drive/My Drive/African_wildlife/images/rhino'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qcn5LhP8pVW3",
    "outputId": "090e11be-f689-459a-e5a1-c92fca6de86c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]\n",
      " ...\n",
      " [0 0 0 1]\n",
      " [0 0 0 1]\n",
      " [0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "BASE_PATH = r\"/content/drive/My Drive/African_wildlife\"\n",
    "IMAGES_PATH = os.path.sep.join([BASE_PATH, \"images\"])\n",
    "ANNOTS_PATH = os.path.sep.join([BASE_PATH, \"annotations\"])\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "imagePaths = []\n",
    "\n",
    "# loop over all CSV files in the annotations directory\n",
    "for csvPath in paths.list_files(ANNOTS_PATH, validExts=(\".csv\")):\n",
    "\t# load the contents of the current CSV annotations file\n",
    "\trows = open(csvPath).read().strip().split(\"\\n\")\n",
    "\n",
    "\t# loop over the rows\n",
    "\tfor row in rows:\n",
    "\t\t# break the row into the filename, bounding box coordinates,\n",
    "\t\t# and class label\n",
    "\t\trow = row.split(\",\")\n",
    "\t\t(filename, startX, startY, endX, endY, label) = row\n",
    "\n",
    "\t\t# derive the path to the input image, load the image (in\n",
    "\t\t# OpenCV format), and grab its dimensions\n",
    "\t\timagePath = os.path.sep.join([IMAGES_PATH, label,\n",
    "\t\t\tfilename])\n",
    "\t\timage = cv2.imread(imagePath)\n",
    "\t\t(h, w) = image.shape[:2]\n",
    "\n",
    "\t\t# load the image and preprocess it\n",
    "\t\timage = load_img(imagePath, target_size=(224, 224))\n",
    "\t\timage = img_to_array(image)\n",
    "\n",
    "\t\t# update our list of data, class labels, bounding boxes, and\n",
    "\t\t# image paths\n",
    "\t\tdata.append(image)\n",
    "\t\tlabels.append(label)\n",
    "\t\timagePaths.append(imagePath)\n",
    "# convert the data, class labels, and image paths to\n",
    "# NumPy arrays, scaling the input pixel intensities from the range\n",
    "# [0, 255] to [0, 1]\n",
    "data = np.array(data, dtype=\"float32\") / 255.0\n",
    "labels = np.array(labels)\n",
    "imagePaths = np.array(imagePaths)\n",
    "\n",
    "# perform one-hot encoding on the labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "\n",
    "print(labels)\n",
    "# only there are only two labels in the dataset, then we need to use\n",
    "# Keras/TensorFlow's utility function as well\n",
    "if len(lb.classes_) == 2:\n",
    "\tlabels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ghy5pGnkEkTJ"
   },
   "outputs": [],
   "source": [
    "#splitting data into training set and test set ; 95%\n",
    "split = train_test_split(data, labels, imagePaths,\n",
    "\ttest_size=0.90, random_state=38)\n",
    "# unpack the data split\n",
    "(testimages, trainimages) = split[:2]\n",
    "(testlabels, trainlabels) = split[2:4]\n",
    "(testpaths, trainpaths) = split[4:]\n",
    "\n",
    "#creating validation set and training1 set from previously created training set; 90%\n",
    "split2 =train_test_split(trainimages,trainlabels,test_size=0.9,random_state=7)\n",
    "\n",
    "(valimages,train1images)=split2[:2] \n",
    "(vallabels,train1labels)=split2[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "da_c9lEPbOc1",
    "outputId": "31c3a35f-d6e9-421c-f2a1-3cbbf388f219"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2296, 224, 224, 3)\n",
      "(255, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train1images.shape)\n",
    "print(valimages.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "67JL8sZbq2Wi"
   },
   "outputs": [],
   "source": [
    "class sequential_model:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.num_of_blocks=0\n",
    "        self.input_shape=[]\n",
    "        self.model=tf.keras.models.Sequential()\n",
    "        self.set_input_shape()\n",
    "        self.add_input_layer(self.input_shape)\n",
    "        self.add_convo_network()\n",
    "        self.add_dense_layer()\n",
    "        self.model.compile(loss='categorical_crossentropy', optimizer='sgd',metrics='accuracy')\n",
    "    \n",
    "    def set_input_shape(self):\n",
    "        print(\"Enter shape of input layer\")\n",
    "        for i in range(3):\n",
    "            ele=int(input())\n",
    "            self.input_shape.append(ele)\n",
    "            \n",
    "    def add_convo_block(self,num_filters,activ,padd):\n",
    "        self.model.add(keras.layers.Conv2D(num_filters, 3, activation=activ, padding=padd))\n",
    "        self.model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "        self.model.add(keras.layers.Dropout(0.5))\n",
    "        \n",
    "        \n",
    "    def add_convo_network(self):\n",
    "        self.num_of_blocks=int(input(\"Enter the no of convolutional blocks you want in your model :\"))\n",
    "        for i in range(self.num_of_blocks):\n",
    "            num_filters=int(input('Enter number of filters :'))\n",
    "            activ=input('Enter activation for layer :')\n",
    "            padd=input('Padding SAME or VALID :')\n",
    "            self.add_convo_block(num_filters,activ,padd)\n",
    "\n",
    "            \n",
    "    def add_input_layer(self,lista):\n",
    "        self.model.add(keras.layers.Input(shape=lista))\n",
    "    \n",
    "    def add_flatten_layer(self):\n",
    "        self.model.add(keras.layers.Flatten())\n",
    "    \n",
    "    def add_dense_layer(self):\n",
    "        x=input('Enter the number of output classes')\n",
    "        self.model.add(keras.layers.Dense(x,activation='softmax'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0ThhSli7QSw"
   },
   "outputs": [],
   "source": [
    "model=sequential_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZbEE2BBQXhlH"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "defaultconv=partial(keras.layers.Conv2D,\n",
    "                    kernel_size=3,activation='relu', padding='VALID')#try changing padding\n",
    "model=keras.models.Sequential([\n",
    "    defaultconv(filters=64,kernel_size=5,input_shape=[224,224,3]),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    \n",
    "    defaultconv(filters=128),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "\n",
    "    defaultconv(filters=256),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    \n",
    "    defaultconv(filters=512),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "\n",
    "    keras.layers.Flatten(),\n",
    "    \n",
    "    keras.layers.Dense(units=4,activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0zDeUumDXmKX"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='sgd',metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FCb5ph4mXqAm",
    "outputId": "8791dd4a-a909-4632-8f56-faf021acc2be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "  2/164 [..............................] - ETA: 4s - loss: 1.4271 - accuracy: 0.4643WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0142s vs `on_train_batch_end` time: 0.0437s). Check your callbacks.\n",
      "164/164 [==============================] - 10s 60ms/step - loss: 1.1727 - accuracy: 0.4490 - val_loss: 1.2057 - val_accuracy: 0.5333\n",
      "Epoch 2/25\n",
      "164/164 [==============================] - 10s 58ms/step - loss: 0.9661 - accuracy: 0.5693 - val_loss: 1.2295 - val_accuracy: 0.4667\n",
      "Epoch 3/25\n",
      "164/164 [==============================] - 10s 59ms/step - loss: 0.9005 - accuracy: 0.6154 - val_loss: 1.0701 - val_accuracy: 0.5451\n",
      "Epoch 4/25\n",
      "164/164 [==============================] - 10s 59ms/step - loss: 0.8077 - accuracy: 0.6581 - val_loss: 1.0768 - val_accuracy: 0.6000\n",
      "Epoch 5/25\n",
      "164/164 [==============================] - 10s 59ms/step - loss: 0.7368 - accuracy: 0.7047 - val_loss: 0.9805 - val_accuracy: 0.6902\n",
      "Epoch 6/25\n",
      "164/164 [==============================] - 10s 60ms/step - loss: 0.6882 - accuracy: 0.7104 - val_loss: 0.9551 - val_accuracy: 0.6980\n",
      "Epoch 7/25\n",
      "164/164 [==============================] - 10s 60ms/step - loss: 0.6262 - accuracy: 0.7487 - val_loss: 0.9204 - val_accuracy: 0.7098\n",
      "Epoch 8/25\n",
      "164/164 [==============================] - 10s 61ms/step - loss: 0.5657 - accuracy: 0.7718 - val_loss: 0.9063 - val_accuracy: 0.7098\n",
      "Epoch 9/25\n",
      "164/164 [==============================] - 10s 61ms/step - loss: 0.4934 - accuracy: 0.8062 - val_loss: 0.7959 - val_accuracy: 0.7569\n",
      "Epoch 10/25\n",
      "164/164 [==============================] - 10s 61ms/step - loss: 0.4638 - accuracy: 0.8214 - val_loss: 0.8564 - val_accuracy: 0.8157\n",
      "Epoch 11/25\n",
      "164/164 [==============================] - 10s 62ms/step - loss: 0.3699 - accuracy: 0.8563 - val_loss: 0.8426 - val_accuracy: 0.7373\n",
      "Epoch 12/25\n",
      "164/164 [==============================] - 10s 62ms/step - loss: 0.3407 - accuracy: 0.8737 - val_loss: 0.7704 - val_accuracy: 0.8078\n",
      "Epoch 13/25\n",
      "164/164 [==============================] - 10s 61ms/step - loss: 0.2757 - accuracy: 0.9016 - val_loss: 0.7723 - val_accuracy: 0.7490\n",
      "Epoch 14/25\n",
      "164/164 [==============================] - 10s 61ms/step - loss: 0.2038 - accuracy: 0.9338 - val_loss: 0.6344 - val_accuracy: 0.8235\n",
      "Epoch 15/25\n",
      "164/164 [==============================] - 10s 61ms/step - loss: 0.1663 - accuracy: 0.9421 - val_loss: 0.5929 - val_accuracy: 0.8314\n",
      "Epoch 16/25\n",
      "164/164 [==============================] - 10s 61ms/step - loss: 0.1051 - accuracy: 0.9673 - val_loss: 0.6044 - val_accuracy: 0.8118\n",
      "Epoch 17/25\n",
      "164/164 [==============================] - 10s 62ms/step - loss: 0.0715 - accuracy: 0.9782 - val_loss: 0.5194 - val_accuracy: 0.8353\n",
      "Epoch 18/25\n",
      "164/164 [==============================] - 10s 62ms/step - loss: 0.0397 - accuracy: 0.9909 - val_loss: 0.4790 - val_accuracy: 0.8196\n",
      "Epoch 19/25\n",
      "164/164 [==============================] - 10s 62ms/step - loss: 0.0234 - accuracy: 0.9948 - val_loss: 0.4769 - val_accuracy: 0.8392\n",
      "Epoch 20/25\n",
      "164/164 [==============================] - 10s 62ms/step - loss: 0.0149 - accuracy: 0.9983 - val_loss: 0.4515 - val_accuracy: 0.8392\n",
      "Epoch 21/25\n",
      "164/164 [==============================] - 10s 62ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.4577 - val_accuracy: 0.8353\n",
      "Epoch 22/25\n",
      "164/164 [==============================] - 10s 61ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.4427 - val_accuracy: 0.8431\n",
      "Epoch 23/25\n",
      "164/164 [==============================] - 10s 61ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4425 - val_accuracy: 0.8392\n",
      "Epoch 24/25\n",
      "164/164 [==============================] - 10s 62ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4410 - val_accuracy: 0.8353\n",
      "Epoch 25/25\n",
      "164/164 [==============================] - 10s 62ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4390 - val_accuracy: 0.8431\n"
     ]
    }
   ],
   "source": [
    "his=model.fit(train1images,train1labels,\n",
    "               validation_data=(valimages,vallabels),\n",
    "               epochs=25,\n",
    "              batch_size=14,\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qnMN3ecjfHjX",
    "outputId": "3023e5ce-1c9e-44d4-c906-444741e7c6db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 220, 220, 64)      4864      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 110, 110, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 108, 108, 128)     73856     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 108, 108, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 52, 52, 256)       295168    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 52, 52, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 73728)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 294916    \n",
      "=================================================================\n",
      "Total params: 1,848,964\n",
      "Trainable params: 1,848,964\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yeLR-jjLiuGX"
   },
   "outputs": [],
   "source": [
    "model.save('/content/drive/MyDrive/African_wildlife/saved_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iwDx8WnvmT6-",
    "outputId": "52f38d96-f2cb-4666-8921-526a3f7a7ed0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 220, 220, 64)      4864      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 110, 110, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 108, 108, 128)     73856     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 108, 108, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 52, 52, 256)       295168    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 52, 52, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 73728)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 294916    \n",
      "=================================================================\n",
      "Total params: 1,848,964\n",
      "Trainable params: 1,848,964\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_now=keras.models.load_model('/content/drive/MyDrive/model_save')\n",
    "model_now.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FTG6dGznXdVw",
    "outputId": "b6665df5-54b3-4857-e1bc-08470c9913b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 51ms/step - loss: 0.3086 - accuracy: 0.9179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.30862945318222046, 0.9179104566574097]"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_now.evaluate(testimages,testlabels)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Training_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
