{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from playsound import playsound\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import numpy as np\n",
    "from imutils import paths\n",
    "import imutils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "modely=keras.models.load_model('Downloads/saved_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 220, 220, 64)      4864      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 110, 110, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 108, 108, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 106, 106, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 53, 53, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 51, 51, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 49, 49, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 47, 47, 256)       590080    \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 23, 23, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 21, 21, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 19, 19, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 17, 17, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 13, 13, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               9437696   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 21,933,876\n",
      "Trainable params: 21,933,876\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelx.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class for creating sequential models\n",
    "class sequential_model:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.num_of_blocks=0\n",
    "        self.input_shape=[]\n",
    "        self.model=tf.keras.models.Sequential()\n",
    "        self.set_input_shape()\n",
    "        self.add_input_layer(self.input_shape)\n",
    "        self.add_convo_network()\n",
    "        self.add_dense_layer()\n",
    "        self.model.compile(loss='categorical_crossentropy', optimizer='sgd',metrics='accuracy')\n",
    "    \n",
    "    def set_input_shape(self):\n",
    "        print(\"Enter shape of input layer\")\n",
    "        for i in range(3):\n",
    "            ele=int(input())\n",
    "            self.input_shape.append(ele)\n",
    "            \n",
    "    def add_convo_block(self,num_filters,activ,padd):\n",
    "        self.model.add(keras.layers.Conv2D(num_filters, 3, activation=activ, padding=padd))\n",
    "        self.model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "        self.model.add(keras.layers.Dropout(0.5))\n",
    "        \n",
    "        \n",
    "    def add_convo_network(self):\n",
    "        self.num_of_blocks=int(input(\"Enter the no of convolutional blocks you want in your model :\"))\n",
    "        for i in range(self.num_of_blocks):\n",
    "            num_filters=int(input('Enter number of filters :'))\n",
    "            activ=input('Enter activation for layer :')\n",
    "            padd=input('Padding SAME or VALID :')\n",
    "            self.add_convo_block(num_filters,activ,padd)\n",
    "\n",
    "            \n",
    "    def add_input_layer(self,lista):\n",
    "        self.model.add(keras.layers.Input(shape=lista))\n",
    "    \n",
    "    def add_flatten_layer(self):\n",
    "        self.model.add(keras.layers.Flatten())\n",
    "    \n",
    "    def add_dense_layer(self):\n",
    "        x=input('Enter the number of output classes')\n",
    "        self.model.add(keras.layers.Dense(x,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=sequential_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = r\"C:\\Users\\VAIBHAV\\Desktop\\african_wildlife\"\n",
    "IMAGES_PATH = os.path.sep.join([BASE_PATH, \"images\"])\n",
    "ANNOTS_PATH = os.path.sep.join([BASE_PATH, \"annotations\"])\n",
    "\n",
    "labels = []\n",
    "\n",
    "# loop over all CSV files in the annotations directory\n",
    "for csvPath in paths.list_files(ANNOTS_PATH, validExts=(\".csv\")):\n",
    "\t# load the contents of the current CSV annotations file\n",
    "\trows = open(csvPath).read().strip().split(\"\\n\")\n",
    "\n",
    "\t# loop over the rows\n",
    "\tfor row in rows:\n",
    "# break the row into the filename, bounding box coordinates,\n",
    "# and class label\n",
    "\t\trow = row.split(\",\")\n",
    "\t\t(filename, startX, startY, endX, endY, label) = row\n",
    "\n",
    "\t\tlabels.append(label)\n",
    "\n",
    "# convert the data, class labels, bounding boxes, and image paths to\n",
    "# NumPy arrays, scaling the input pixel intensities from the range\n",
    "# [0, 255] to [0, 1]\n",
    "\n",
    "labels = np.array(labels)\n",
    "\n",
    "#one-hot encoding on the labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "if len(lb.classes_) == 2:\n",
    "\tlabels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zebra\n",
      "buffalo\n"
     ]
    }
   ],
   "source": [
    "#path from we have to pick photos\n",
    "testpath = r'C:\\Users\\VAIBHAV\\Desktop\\african_wildlife\\testpath'\n",
    "\n",
    "#looping over every image in source path\n",
    "for subdir, dirs, files in os.walk(testpath):\n",
    "    for file in files:\n",
    "        imagePath=os.path.join(subdir, file)\n",
    "        image = load_img(imagePath, target_size=(224, 224))\n",
    "        image = img_to_array(image) / 255.0\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "\n",
    "\n",
    "        labelPreds=modely.predict(image)\n",
    "#i is of the maximum value from predicted classes\n",
    "        i = np.argmax(labelPreds, axis=1)\n",
    "        label = lb.classes_[i][0]\n",
    "\n",
    "        print(label)\n",
    "        image = cv2.imread(imagePath)\n",
    "        image = imutils.resize(image, width=600)\n",
    "        (h, w) = image.shape[:2]\n",
    "\n",
    "\n",
    "        cv2.imshow('window',image)\n",
    "        cv2.waitKey(2000)\n",
    "\n",
    "        if label=='zebra':\n",
    "            playsound(r'C:\\Users\\VAIBHAV\\Desktop\\african_wildlife\\sound\\zebrasound.mp3')\n",
    "        elif label=='elephant':\n",
    "            playsound(r'C:\\Users\\VAIBHAV\\Desktop\\african_wildlife\\sound\\elephantsound.mp3')\n",
    "        elif label=='rhino':\n",
    "            playsound(r'C:\\Users\\VAIBHAV\\Desktop\\african_wildlife\\sound\\rhinosound.mp3')\n",
    "        elif label=='buffalo':\n",
    "            playsound(r'C:\\Users\\VAIBHAV\\Desktop\\african_wildlife\\sound\\bullsound.mp3')\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import os\n",
    "\n",
    "global i\n",
    "i=0\n",
    "path = r'C:\\Users\\VAIBHAV\\Desktop\\african_wildlife\\testpath'\n",
    "class web_c:\n",
    "\n",
    "\n",
    "    def start_wc(self):\n",
    "        timeout = time.time() + 3\n",
    "        cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "        if not cap.isOpened():\n",
    "            raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            frame = cv2.resize(frame, None, fx=0.5, fy=0.5)\n",
    "            cv2.imshow('Input', frame)\n",
    "            global i\n",
    "\n",
    "            cv2.imwrite(os.path.join(path,\"img+\"+str(i)+\".jpg\"),frame )\n",
    "            i=i+1\n",
    "            print(i)\n",
    "            c = cv2.waitKey(1)\n",
    "            if c == 27 or time.time() > timeout or i==5:\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                break\n",
    "\n",
    "wc = web_c()\n",
    "wc.start_wc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
